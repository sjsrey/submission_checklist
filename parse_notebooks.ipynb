{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5115e98-6f3f-4602-aaa0-ef6797a2fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'file_list'\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c57e4674-cc6e-418e-b7af-0d85d8c1b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the parsed data\n",
    "data = []\n",
    "\n",
    "# Open the file and process each line\n",
    "with open(f, 'r') as file:\n",
    "    for line in file:\n",
    "        # Strip leading/trailing whitespace\n",
    "        line = line.strip()\n",
    "\n",
    "        # Split on the first colon only\n",
    "        if ':' in line:\n",
    "            file_name, code = line.split(':', 1)\n",
    "\n",
    "            # Strip leading/trailing spaces\n",
    "            file_name = file_name.strip()\n",
    "            code = code.strip()\n",
    "\n",
    "            # Append the parsed information as a tuple to the data list\n",
    "            data.append((file_name, code))\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "df = pd.DataFrame(data, columns=['File Name', 'Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c0f985c-7ca2-44dd-abfd-c4411235eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2929e886-a3ec-45a3-9824-f29eeb3eadf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150_segregation.py</td>\n",
       "      <td>hdf = gpd.read_file(\"../data/results/hood_congruence.csv\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150_segregation.py</td>\n",
       "      <td>sdf = gpd.read_file(\"../data/results/school_congruence.csv\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150_segregation.py</td>\n",
       "      <td>hoods = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_maxp.parquet\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150_segregation.py</td>\n",
       "      <td>sabs = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_sabs.parquet\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>052_diversity.py</td>\n",
       "      <td>place_csv = pandas.read_csv(\"../data/sample_places.csv\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>052_diversity.py</td>\n",
       "      <td>hoods = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_maxp.parquet\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>052_diversity.py</td>\n",
       "      <td>sabs = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_sabs.parquet\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>052_diversity.py</td>\n",
       "      <td>hdf.to_csv(\"../data/results/hood_diversity.csv\", index=False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>052_diversity.py</td>\n",
       "      <td>sdf.to_csv(\"../data/results/school_diversity.csv\", index=False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>010_import_msas.py</td>\n",
       "      <td>acs18 = gpd.read_parquet(\"../data/acs_2018_tract.parquet\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>010_import_msas.py</td>\n",
       "      <td>acs18 = gpd.read_parquet(\"s3://spatial-ucr/census/acs/acs_2018_tract.parquet\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>010_import_msas.py</td>\n",
       "      <td>pandas.Series(place_list, name=\"places\").to_frame().to_csv(\"../data/sample_places.csv\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>250_district_results.ipynb</td>\n",
       "      <td>\"    place_hoods = gpd.read_parquet(f'../data/neighborhoods/{place}_interpolated_maxp.parquet')\\n\",</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File Name  \\\n",
       "0           150_segregation.py   \n",
       "1           150_segregation.py   \n",
       "2           150_segregation.py   \n",
       "3           150_segregation.py   \n",
       "4             052_diversity.py   \n",
       "5             052_diversity.py   \n",
       "6             052_diversity.py   \n",
       "7             052_diversity.py   \n",
       "8             052_diversity.py   \n",
       "9           010_import_msas.py   \n",
       "10          010_import_msas.py   \n",
       "11          010_import_msas.py   \n",
       "12  250_district_results.ipynb   \n",
       "\n",
       "                                                                                                   Code  \n",
       "0                                            hdf = gpd.read_file(\"../data/results/hood_congruence.csv\")  \n",
       "1                                          sdf = gpd.read_file(\"../data/results/school_congruence.csv\")  \n",
       "2                          hoods = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_maxp.parquet\")  \n",
       "3                           sabs = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_sabs.parquet\")  \n",
       "4                                              place_csv = pandas.read_csv(\"../data/sample_places.csv\")  \n",
       "5                          hoods = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_maxp.parquet\")  \n",
       "6                           sabs = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_sabs.parquet\")  \n",
       "7                                         hdf.to_csv(\"../data/results/hood_diversity.csv\", index=False)  \n",
       "8                                       sdf.to_csv(\"../data/results/school_diversity.csv\", index=False)  \n",
       "9                                            acs18 = gpd.read_parquet(\"../data/acs_2018_tract.parquet\")  \n",
       "10                       acs18 = gpd.read_parquet(\"s3://spatial-ucr/census/acs/acs_2018_tract.parquet\")  \n",
       "11              pandas.Series(place_list, name=\"places\").to_frame().to_csv(\"../data/sample_places.csv\")  \n",
       "12  \"    place_hoods = gpd.read_parquet(f'../data/neighborhoods/{place}_interpolated_maxp.parquet')\\n\",  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4652aad-a4bb-4599-b7dd-ec7ef48ab0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       hdf = gpd.read_file(\"../data/results/hood_congruence.csv\")\n",
       "1                     sdf = gpd.read_file(\"../data/results/school_congruence.csv\")\n",
       "2     hoods = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_maxp.parquet\")\n",
       "3      sabs = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_sabs.parquet\")\n",
       "4                         place_csv = pandas.read_csv(\"../data/sample_places.csv\")\n",
       "                                          ...                                     \n",
       "73    hoods = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_maxp.parquet\")\n",
       "74     sabs = gpd.read_parquet(f\"{neighbordir}/{place}_interpolated_sabs.parquet\")\n",
       "75                  hdf.to_csv(\"../data/results/hood_congruence.csv\", index=False)\n",
       "76                sdf.to_csv(\"../data/results/school_congruence.csv\", index=False)\n",
       "77                         mdf.to_csv(\"../data/results/metrobpg.csv\", index=False)\n",
       "Name: Code, Length: 78, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15342477-5460-4ba8-8116-f6490db6e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_path(code_line):\n",
    "    # Regular expression to capture file paths in .to_csv(), .read_parquet(), etc.\n",
    "    pattern = r'[\\w\\.]+\\((?:f?[\"\\'])(.*?)(?:[\"\\'])'\n",
    "    \n",
    "    # Find all matches in the code line\n",
    "    match = re.findall(pattern, code_line)\n",
    "    \n",
    "    # Return the first match if found, otherwise None\n",
    "    return match[0] if match else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "590b0ca1-32e4-4928-ba38-ae47bc7b25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['extracted_paths'] = df['Code'].apply(extract_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2fb2c64-b5c7-4b12-a6eb-19dad83abe66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 ../data/results/hood_congruence.csv\n",
       "1               ../data/results/school_congruence.csv\n",
       "2     {neighbordir}/{place}_interpolated_maxp.parquet\n",
       "3     {neighbordir}/{place}_interpolated_sabs.parquet\n",
       "4                           ../data/sample_places.csv\n",
       "                           ...                       \n",
       "73    {neighbordir}/{place}_interpolated_maxp.parquet\n",
       "74    {neighbordir}/{place}_interpolated_sabs.parquet\n",
       "75                ../data/results/hood_congruence.csv\n",
       "76              ../data/results/school_congruence.csv\n",
       "77                       ../data/results/metrobpg.csv\n",
       "Name: extracted_paths, Length: 78, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.extracted_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d656571-94a7-451d-b56c-358e66cb022c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            hood_congruence.csv\n",
       "1          school_congruence.csv\n",
       "2     _interpolated_maxp.parquet\n",
       "3     _interpolated_sabs.parquet\n",
       "4              sample_places.csv\n",
       "                 ...            \n",
       "73    _interpolated_maxp.parquet\n",
       "74    _interpolated_sabs.parquet\n",
       "75           hood_congruence.csv\n",
       "76         school_congruence.csv\n",
       "77                  metrobpg.csv\n",
       "Name: extracted_paths, Length: 78, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.extracted_paths.str.split(\"/\").str[-1].str.split(\"}\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb428c7d-d614-44b2-8f10-2bc1084619ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
